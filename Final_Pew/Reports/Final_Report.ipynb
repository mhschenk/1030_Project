{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technology and Politics: Posting about Politics on Social Media  \n",
    "Marie Schenk  \n",
    "Data Science Initiative and Political Science Dept., Brown University\n",
    "December 3, 2019  \n",
    "GitHub Repository: https://github.com/mhschenk/1030_Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Who uses social media to post political hashtags? How are people's attitudes about social media and technology related to their habits of posting about politics online? And, how does data science, as opposed to the field of political science, help us address these questions that lie at the intersection of technology and politics?\n",
    "\n",
    "To answer these questions, I am using Wave 35 of Pew Research Center's American Trends Panel. This wave of the ongoing survey was fielded between May 29 and June 11, 2018. It includes questions about internet and social media usage, beliefs about technology's place in society, and political and demographic statistics. The target feature is the question, \"In the past year, have you used hastags related to a political or social issue?\" This is a yes-or-no question, which means that my analysis is a classification problem. I chose this feature because political hashtags have become a critical part of the political system, both by going viral online and by earning coverage in traditional media outlets. Yet, little is understood about who engages in this sort of online activism. \n",
    "\n",
    "This project relates to my dissertation in political science, which focuses on how online spaces become politicized. I am looking at this in the context of what Jane Mansbridge calls “everyday political talk” (Mansbridge 1993). Everyday talk may not be overtly political, in that it does not name public policies or political institutions, but it nevertheless addresses issues that impact public life. Everyday talk and public deliberation have been a topic of interest for political scientists for years, but most work focuses on spaces such as cafes or public meetings, not virtual spaces (Walsh 2004). The advent of social media has dramatically changed the structure of public life; many of the activities that used to occur in public spaces, such as coffee shops, now take place in virtual spaces, like Twitter threads. This project contributes to the larger project of my dissertation by helping me understand if online discussions are similar to other, more widely studied forms of political engagement. It is well established in political science, for example, that people who vote tend to be older and more highly educated than average. Yet online activism is generally perceived to be a space dominated by younger generations of \"digital natives.\" In what ways is talking about politics online similar to voting, and in what ways is it different? This will help me create expectations for my future work, based on what existing theories I think are most likely to apply to online political discussions.\n",
    "\n",
    "I am particularly interested in exploring the differences between a data-science approach to answering this question and a political science approach. In the Outlook section of this report, I reflect upon methodology in addition to my findings. How would a data scientist go about answering this question, and how does that compare to a political scientist's toolbox? What are the benefits of these distinct approaches? How can I combine them in my future work to contribute meaningfully to both fields?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Exploratory data analysis confirms many existing expectations from past political science research. For example, the majority of respondents did not use political hashtags when posting online. Those who do not post about politics are slightly older, but there is wide variance here. Furthermore, those who do not use social media at all tend to be older. In short, political activity is relatively rare, and internet useage is negatively correlated with age. \n",
    "\n",
    "![posting by age](boxplot_age.png)<figcaption> Fig. 1 A boxplot of respondents who use political hashtags by age category. <figcaption>\n",
    "    \n",
    "We again see how rare political activity is when looking at the count of political posts crossed with voter registration. Posting political hashtags is rare behavior, and it seems relatively uncorrelated with voter registration. Note the high number of respondents who report that they're registered to vote, which far outstrips typical voter turnout. This is likely due to the fact that registration is self-reported, and people tend to lie because they know that voting is a socially desirable behavior. Although, since this is a panel that people opt into, there is probably a slightly higher rate of civic engagement among respondents as compared to the general population. \n",
    "\n",
    "![posting by vote](stacked_bar_count.png)<figcaption> Fig. 2 A bar graph of self-reported voter-registration and posting political hashtags.<figcaption>\n",
    "\n",
    "    \n",
    "While online political activity seems somewhat correlated with demographic and political variables, it shows little correlation with trust in technology companies. This indicates that a person's descision whether or not to engage in online political activism has more to do with their political inclinations than with their evaluation of the trustworthiness of internet companies. To me, this indicates that online political behavior may have more in common with other political acts than with other online behavior. \n",
    "    \n",
    "![posting by trust](boxplot_trust.png)<figcaption> Fig. 3 A boxplot of using political hashtags by trust in technology companies. <figcaption>\n",
    "    \n",
    "A correlation matrix reveals some interesting possibilities. The ten most correlated features  are: social media is important for getting involved in political issues (politics_issues), social media is important as a place to exress political opinions (politics_express), using Twitter (Twitter), social media is important for finding others who share your political opinion (Politics_others), using Instagram (Instagram), social media is important for creating sustained movements for social change (Social_Mvts), how many of the stories in your Facebook news feed do you find interesting (FB_interesting), age (Age), and how much do you agree that social media highlights important issues that might not get a lot of attention otherwise (Imp_Issues).\n",
    "    \n",
    "![correlation matrix](corr_coeff_FINAL.png) <figcaption> Fig. 4 Matrix of the top ten features most correlated with using political hashtags. <figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "This survey consists entirely of binary and ordinal data, with some categorical data in the demographic information. As with virtually all social science surveys, missing data is a significant concern in this survey. In fact, there are two missing value codes in this dataset. The first, 99, is used when a respondent did not answer a question for some reason. Rows with this kind of missingness were dropped, bringing the number of observations from 4,594 to 3,604. The second kind of missingness, coded by Pew as NA, occurs when a respondent was not asked a question at all. This occurred either because the question was part of a survey experiment in which subsets of the panel were asked different versions of the question, or when an earlier answer indicated that a question would not apply to a respondent. Most notably, respondents who indicated early in the survey that they do not use social media (or do not use certain platforms) were not asked additional questions about the way they use social media (or that particular platform). Since this represents interesting data in and of itself, these responses were given their own value within the dataset and were given their own category in one-hot and ordinal encoded data. However, for simplicity, respondents who were not asked the target variable were dropped from the dataset, making this an evaluation of political behavior online among those who use social media. The final number of rows included in the analysis is 3,394. Before dropping any rows, I dropped columns that represented survey experiments, those that had a large number of missing values (such as a set of questions only asked to parents of minor children), and weights and respondent IDs. \n",
    "\n",
    "I produced machine learning pipelines for three models: logistic regression with L1 penalty (lasso), random forest classification, and support vector classificaiton. I produced code that would allow me to tune the relevant parameters: C; maximum depth and minimum samples for a split; and gamma and C, respectively. I will compare accuracy of the models to the balance of the dataset. Uncertainty is introduced by the random state. This influences the way the data is split into test and train sets. For random forests, it also influences the way the decision trees are constructed. To account for this uncertainty, I will run the pipeline multiple times and average the accuracy score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Of the respondents included in the analysis, 84.6% did not post political hashtags on social media. Thus, the baseline accuracy would be to guess 0 for every respondent, and we would be correct about 84.6% of the time. The random forest classifier did not improve on this baseline accuracy (average accuracy was 0.84, with standard deviation of +/- 0.02). After running through 5 different random states on my logistic regression model, I got an average accuracy of 0.86, with standard deviation of +/- 0.01. My SVC model failed to produce a result in a reasonable amout of time. Thus, I further explored my logistic regression model. \n",
    "\n",
    "All five runs of the pipeline produced an ideal C parameter of 0.1. A benefit of the logistic regression model is that it is relatively easy to interpret. I produced a table showing the top twenty features and the associated coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![coefficients table](Coeff_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients are all extremely small. This model, frankly, will not revolutionize the study of online politics. However, some interesting patterns emerge from this list of features. Other online political behavior predicts the use of political hashtags. People who think of social media as a place where they make valuable political connections and can have an impact on policy are more likely to use political hashtags. One result I found especially interesting is that seeing content about race and immigration is correlated, while similar questions about seeing content about sexual harrassment and gun violence are not. While this model does not provide enough information to provide any explanations for this finding, they are interesting and warrant further study. This model provides a path forward for myself and other political scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "\n",
    "There are several improvements I would make for future analyses of this dataset. The first would be to include respondents who don't use social media at all as a category in the target feature. For simplicity, I made the feature truly binary and only included social media users who did and did not post about politics, but including people who do not use social media could change the interpretation. Another change would be to encode the ordinal features as ordinal, rather than using the one-hot encoder. This was another choice made for simplicity, but the downside is that it sacrifices some of the information in the ordinal features. Finally, I could sample from the dataset to make a balanced dataset, which would be a better way to train the model, then deploy it on a full dataset. \n",
    "\n",
    "In terms of the differences between a data science approach to this question and a political science approach, I see two major differences. The first is that political science would use weights to adjust for differences in the demographics of the population as compared to the recruited sample. The second is that a statistical approach to analyzing this data would prioritize forming hypotheses about what variables matter most in advance, and testing only a limited number of models. Ultimately, I think the biggest contribution from data science to political science will come from data science analysis of big data sets generated as a by-product of daily life, such as data scraped from a social media site. These datasets are too large for traditional statistical approaches to make any sense of. In order for political scientists to explore this kind of data, they will have to make alliances with data scientists who can lead the way. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Mansbridge, Jane. 1993. “Everyday Talk in the Deliberative System.” In *Deliberative Politics: Essays on Democracy and Disagreement,* ed. Stephen Macedo. Cary, UNITED STATES: Oxford University Press.\n",
    "\n",
    "Pew Research Center. 2018. American Trends Panel, Wave 35. Dataset available for download, https://www.pewresearch.org/internet/dataset/american-trends-panel-wave-35/.\n",
    "\n",
    "Walsh, Katherine Cramer. 2004. *Talking About Politics : Informal Groups and Social Identity in American Life.* Chicago: University of Chicago Press.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
